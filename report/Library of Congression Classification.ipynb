{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812a42b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from iml_group_proj.config import RANDOM_STATE\n",
    "from iml_group_proj.evaluation import evaluate_many\n",
    "from iml_group_proj.data.utils import load_libofc_df\n",
    "from iml_group_proj.data.preprocess import AverageEmbeddingsPerRecord, DataMode\n",
    "from iml_group_proj.data.embeddings import EmbeddingsDataLoader, EmbeddingsType\n",
    "from iml_group_proj.trainer import train_model, maybe_load_model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcd2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../github_data\"\n",
    "CACHE_DIR = \"../_cache/\"\n",
    "def experiment_to_file_path(experiment, model_name):\n",
    "    return os.path.join(CACHE_DIR, f\"{experiment[0]}_{experiment[1]}_{model_name}.pk\")\n",
    "        \n",
    "def get_experiment_result(embeddings_type, data_mode, models):\n",
    "    print(f\"Starting experiment with {embeddings_type} embeddings with {data_mode}\")\n",
    "    data = EmbeddingsDataLoader.load(DATA_PATH, embeddings_type)\n",
    "    X_train, y_train, X_test, y_test = AverageEmbeddingsPerRecord.prep(data, embeddings_type, data_mode)\n",
    "    \n",
    "    trained_models = []\n",
    "    for model in models:\n",
    "        trained_model = train_model(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            {\"embeddings_type\": embeddings_type, \"data\": data_mode},\n",
    "            experiment_to_file_path((embeddings_type, data_mode), model[2])\n",
    "        )\n",
    "        \n",
    "        trained_models.append(trained_model)\n",
    "    print(\"Evaluating\")\n",
    "    result_dicts = evaluate_many(trained_models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    return result_dicts, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "249cc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining each experiment settings\n",
    "embeddings_types = [\n",
    "    EmbeddingsType.TFIDF, \n",
    "    EmbeddingsType.W2V,\n",
    "    EmbeddingsType.BERT_XS,\n",
    "    EmbeddingsType.BERT_S,\n",
    "    EmbeddingsType.BERT_L\n",
    "]\n",
    "\n",
    "data_types = [DataMode.title_only, DataMode.synopsis_only, DataMode.both_title_synopsis]\n",
    "\n",
    "experiments = list(itertools.product(embeddings_types[-1:], data_types))\n",
    "\n",
    "models = [\n",
    "        (MLPClassifier(random_state=1, max_iter=250, hidden_layer_sizes=(600, 600), early_stopping=True), None, 'MLP'),\n",
    "        (SVC(C=100, kernel=\"rbf\", gamma=0.001, random_state=RANDOM_STATE), None, \"SVC\"),\n",
    "        (GaussianNB(), None,'NaiveBayes'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95daf32d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                    | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with bert_large embeddings with title\n",
      "Model found at ../_cache/bert_large_title_MLP.pk, skip training flow...\n",
      "Model found at ../_cache/bert_large_title_SVC.pk, skip training flow...\n",
      "Model found at ../_cache/bert_large_title_NaiveBayes.pk, skip training flow...\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████████████████████████████▋                                                                                                       | 1/3 [09:10<18:20, 550.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  f1_score        name embeddings_type   data  \\\n",
      "0  0.776502   0.785875  0.770462  0.774476         MLP      bert_large  title   \n",
      "1  0.612667   0.629817  0.612667  0.614628         MLP      bert_large  title   \n",
      "2  0.791859   0.798189  0.789916  0.792634         SVC      bert_large  title   \n",
      "3  0.623667   0.633828  0.623667  0.625870         SVC      bert_large  title   \n",
      "4  0.415615   0.466178  0.406159  0.399275  NaiveBayes      bert_large  title   \n",
      "5  0.390333   0.435434  0.390333  0.376867  NaiveBayes      bert_large  title   \n",
      "\n",
      "  best_params  is_train  \n",
      "0          {}      True  \n",
      "1          {}     False  \n",
      "2          {}      True  \n",
      "3          {}     False  \n",
      "4          {}      True  \n",
      "5          {}     False  \n",
      "Starting experiment with bert_large embeddings with synopsis\n",
      "Model not found at ../_cache/bert_large_synopsis_MLP.pk, training MLP\n",
      "Finished training!\n",
      "Saving the model to ../_cache/bert_large_synopsis_MLP.pk...\n",
      "Model not found at ../_cache/bert_large_synopsis_SVC.pk, training SVC\n",
      "Finished training!\n",
      "Saving the model to ../_cache/bert_large_synopsis_SVC.pk...\n",
      "Model not found at ../_cache/bert_large_synopsis_NaiveBayes.pk, training NaiveBayes\n",
      "Finished training!\n",
      "Saving the model to ../_cache/bert_large_synopsis_NaiveBayes.pk...\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                   | 2/3 [19:50<10:03, 603.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  f1_score        name embeddings_type  \\\n",
      "0  0.939473   0.941114  0.938654  0.939121         MLP      bert_large   \n",
      "1  0.733000   0.740670  0.733000  0.733635         MLP      bert_large   \n",
      "2  0.868565   0.870096  0.867949  0.868584         SVC      bert_large   \n",
      "3  0.740667   0.745303  0.740667  0.741442         SVC      bert_large   \n",
      "4  0.550850   0.566894  0.548818  0.549518  NaiveBayes      bert_large   \n",
      "5  0.532000   0.554923  0.532000  0.533312  NaiveBayes      bert_large   \n",
      "\n",
      "       data best_params  is_train  \n",
      "0  synopsis          {}      True  \n",
      "1  synopsis          {}     False  \n",
      "2  synopsis          {}      True  \n",
      "3  synopsis          {}     False  \n",
      "4  synopsis          {}      True  \n",
      "5  synopsis          {}     False  \n",
      "Starting experiment with bert_large embeddings with both\n",
      "Model not found at ../_cache/bert_large_both_MLP.pk, training MLP\n",
      "Finished training!\n",
      "Saving the model to ../_cache/bert_large_both_MLP.pk...\n",
      "Model not found at ../_cache/bert_large_both_SVC.pk, training SVC\n",
      "Finished training!\n",
      "Saving the model to ../_cache/bert_large_both_SVC.pk...\n",
      "Model not found at ../_cache/bert_large_both_NaiveBayes.pk, training NaiveBayes\n",
      "Finished training!\n",
      "Saving the model to ../_cache/bert_large_both_NaiveBayes.pk...\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [45:09<00:00, 903.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  f1_score        name embeddings_type  data  \\\n",
      "0  0.884667   0.886185  0.884055  0.883845         MLP      bert_large  both   \n",
      "1  0.756000   0.757956  0.756000  0.755128         MLP      bert_large  both   \n",
      "2  0.985270   0.985303  0.985235  0.985253         SVC      bert_large  both   \n",
      "3  0.751333   0.754292  0.751333  0.751922         SVC      bert_large  both   \n",
      "4  0.538902   0.564191  0.534759  0.533341  NaiveBayes      bert_large  both   \n",
      "5  0.506667   0.535751  0.506667  0.503779  NaiveBayes      bert_large  both   \n",
      "\n",
      "  best_params  is_train  \n",
      "0          {}      True  \n",
      "1          {}     False  \n",
      "2          {}      True  \n",
      "3          {}     False  \n",
      "4          {}      True  \n",
      "5          {}     False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict_list = []\n",
    "trained_models_list = []\n",
    "for (embeddings_type, data_type) in tqdm(experiments):\n",
    "    result_dicts, trained_models = get_experiment_result(embeddings_type, data_type, models)\n",
    "    print(pd.DataFrame(result_dicts))\n",
    "    trained_models_list.extend(trained_models)\n",
    "    result_dict_list.extend(result_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cb14a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_df = pd.DataFrame(result_dict_list)\n",
    "#final_result_df.to_csv(\"../_output/experiments_result_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3735d574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>name</th>\n",
       "      <th>embeddings_type</th>\n",
       "      <th>data</th>\n",
       "      <th>best_params</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776502</td>\n",
       "      <td>0.785875</td>\n",
       "      <td>0.770462</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>MLP</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>title</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612667</td>\n",
       "      <td>0.629817</td>\n",
       "      <td>0.612667</td>\n",
       "      <td>0.614628</td>\n",
       "      <td>MLP</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>title</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791859</td>\n",
       "      <td>0.798189</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.792634</td>\n",
       "      <td>SVC</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>title</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.623667</td>\n",
       "      <td>0.633828</td>\n",
       "      <td>0.623667</td>\n",
       "      <td>0.625870</td>\n",
       "      <td>SVC</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>title</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.415615</td>\n",
       "      <td>0.466178</td>\n",
       "      <td>0.406159</td>\n",
       "      <td>0.399275</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>title</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.390333</td>\n",
       "      <td>0.435434</td>\n",
       "      <td>0.390333</td>\n",
       "      <td>0.376867</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>title</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.939473</td>\n",
       "      <td>0.941114</td>\n",
       "      <td>0.938654</td>\n",
       "      <td>0.939121</td>\n",
       "      <td>MLP</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>synopsis</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.740670</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.733635</td>\n",
       "      <td>MLP</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>synopsis</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.868565</td>\n",
       "      <td>0.870096</td>\n",
       "      <td>0.867949</td>\n",
       "      <td>0.868584</td>\n",
       "      <td>SVC</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>synopsis</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.740667</td>\n",
       "      <td>0.745303</td>\n",
       "      <td>0.740667</td>\n",
       "      <td>0.741442</td>\n",
       "      <td>SVC</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>synopsis</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.550850</td>\n",
       "      <td>0.566894</td>\n",
       "      <td>0.548818</td>\n",
       "      <td>0.549518</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>synopsis</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.554923</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.533312</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>synopsis</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.884667</td>\n",
       "      <td>0.886185</td>\n",
       "      <td>0.884055</td>\n",
       "      <td>0.883845</td>\n",
       "      <td>MLP</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>both</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.757956</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.755128</td>\n",
       "      <td>MLP</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>both</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.985270</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>0.985235</td>\n",
       "      <td>0.985253</td>\n",
       "      <td>SVC</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>both</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.751333</td>\n",
       "      <td>0.754292</td>\n",
       "      <td>0.751333</td>\n",
       "      <td>0.751922</td>\n",
       "      <td>SVC</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>both</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.538902</td>\n",
       "      <td>0.564191</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.533341</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>both</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.535751</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.503779</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>bert_large</td>\n",
       "      <td>both</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall  f1_score        name embeddings_type  \\\n",
       "0   0.776502   0.785875  0.770462  0.774476         MLP      bert_large   \n",
       "1   0.612667   0.629817  0.612667  0.614628         MLP      bert_large   \n",
       "2   0.791859   0.798189  0.789916  0.792634         SVC      bert_large   \n",
       "3   0.623667   0.633828  0.623667  0.625870         SVC      bert_large   \n",
       "4   0.415615   0.466178  0.406159  0.399275  NaiveBayes      bert_large   \n",
       "5   0.390333   0.435434  0.390333  0.376867  NaiveBayes      bert_large   \n",
       "6   0.939473   0.941114  0.938654  0.939121         MLP      bert_large   \n",
       "7   0.733000   0.740670  0.733000  0.733635         MLP      bert_large   \n",
       "8   0.868565   0.870096  0.867949  0.868584         SVC      bert_large   \n",
       "9   0.740667   0.745303  0.740667  0.741442         SVC      bert_large   \n",
       "10  0.550850   0.566894  0.548818  0.549518  NaiveBayes      bert_large   \n",
       "11  0.532000   0.554923  0.532000  0.533312  NaiveBayes      bert_large   \n",
       "12  0.884667   0.886185  0.884055  0.883845         MLP      bert_large   \n",
       "13  0.756000   0.757956  0.756000  0.755128         MLP      bert_large   \n",
       "14  0.985270   0.985303  0.985235  0.985253         SVC      bert_large   \n",
       "15  0.751333   0.754292  0.751333  0.751922         SVC      bert_large   \n",
       "16  0.538902   0.564191  0.534759  0.533341  NaiveBayes      bert_large   \n",
       "17  0.506667   0.535751  0.506667  0.503779  NaiveBayes      bert_large   \n",
       "\n",
       "        data best_params  is_train  \n",
       "0      title          {}      True  \n",
       "1      title          {}     False  \n",
       "2      title          {}      True  \n",
       "3      title          {}     False  \n",
       "4      title          {}      True  \n",
       "5      title          {}     False  \n",
       "6   synopsis          {}      True  \n",
       "7   synopsis          {}     False  \n",
       "8   synopsis          {}      True  \n",
       "9   synopsis          {}     False  \n",
       "10  synopsis          {}      True  \n",
       "11  synopsis          {}     False  \n",
       "12      both          {}      True  \n",
       "13      both          {}     False  \n",
       "14      both          {}      True  \n",
       "15      both          {}     False  \n",
       "16      both          {}      True  \n",
       "17      both          {}     False  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
